% Created 2016-03-08 Tue 01:10
\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{fixltx2e}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{float}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{marvosym}
\usepackage{wasysym}
\usepackage{amssymb}
\usepackage{hyperref}
\tolerance=1000
\usepackage{minted}
\author{Nicholas Mitchell}
\date{\today}
\title{Application for new LRZ account}
\hypersetup{
  pdfkeywords={},
  pdfsubject={},
  pdfcreator={Emacs 24.5.1 (Org mode 8.2.10)}}
\begin{document}

\maketitle
\tableofcontents

\pagebreak

\section{User information}
\label{sec-1}

\begin{center}
\begin{tabular}{l|l}
\textbf{Name} & Nicholas Mitchell\\
\textbf{Phone} & +49 15757 954 968\\
\textbf{Email} & nicholas.william.mitchell@student.uni-augsburg.de\\
\textbf{Nationality} & British\\
\end{tabular}
\end{center}

\section{Description of project}
\label{sec-2}

Within the framework of his Master thesis the user performs statistical analysis of financial markets in combination with social media data (sentiment analysis) in an attempt to better explain uncertainty within the market and to ultimately increase predictive accuracy of current models, which do not include novel data such as sentiment analysis.\newline

\noindent
The sentiment analysis work has already been completed, meaning all the text-information has now been quantified, ready to combine with e.g. stock market returns. Several combinations of the data are selected to compare subsets containing differing information.\\\

\noindent
The work includes the usage of component-wise gradient boosting, allowing robust modelling of wide data sets (p > n) due to the inherent nature of variable selection that the method presents. Variants of gradient boosting are also implemented, including the usage of Bernoulli/Binomial distributions and stochastic gradient boosting. There are a relatively large number of hyper parameters that must be tuned, which means a large amount of computational time - cross-validation efforts especially contributing to the final run-time. Results are to be compared to standard modelling techniques such as AR(n) models.

\section{Tool-set}
\label{sec-3}

\noindent
Python was used for the collection of sentiment analysis. The algorithms that scored the text for its sentiment were written in a host of languages.
From this point on, however, R will likely be the sole programming language.
The algorithms that consume the most time include the gradient descent algorithm i.e. the minimisation of the relevant loss-function and then 25-fold bootstrap cross-validation of the results. Within R, the main packages used include:

\begin{itemize}
\item mboost
\item caret
\item gbm
\item doParallel/doMC
\item data.table
\end{itemize}
% Emacs 24.5.1 (Org mode 8.2.10)
\end{document}