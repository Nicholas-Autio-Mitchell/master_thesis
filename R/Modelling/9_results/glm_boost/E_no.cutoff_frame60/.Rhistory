library(mboost)
library(caret)
library(data.table)
library(multilevelPSA)
library(doParallel)
this_folder <- getwd()
this_folder
load(paste0(this_folder, "/subsets_lagged.rda"))
source(paste0(this_folder, "/corr_pruner.R"))
source(paste0(this_folder, "/error_functions.R"))
source(paste0(this_folder, "/results_template.R"))
source(paste0(this_folder, "/ultra_modeller.R"))
registerDoParallel(4)
input_data <- sapply(c("Lag.1", "Lag.2", "Lag.3", "Lag.4", "Lag.5"), function(x) NULL)
input_subsets <- sapply(c("trad_small", "trad_large", "sent_small", "sent_large", "combined"), function(x) NULL)
for(i in 1:length(input_data)){input_data[[i]] <- input_subsets}
## Assistance:
## subsets_lagged[[4]][[3]]   --> first index is the lag value, here Lag.4 [(i-1) = lag]
##                            --> second index is the subset.  1 = trad_small
##                                                             2 = trad_large
##                                                             3 = sent_small
##                                                             4 = sent_large
##                                                             5 = combined
## Need to run this each time too to take a fresh copy of the data. DOW.DP is removed by reference otherwise
raw_data <- copy(subsets_lagged)
for(i in 1:5) {
for(j in 1:5) {
input_data[[i]][[j]] <- corr_pruner(raw_data[[i]][[j]],
cutoff = 0.8,
plot = FALSE,
print.removed = FALSE)
}
}
## ---------------------------------------------------------- ##
##  Flatten the list so that all available cores can be used  ##
## ---------------------------------------------------------- ##
## Flatten
input_data.one_list <- unlist(input_data, recursive = FALSE)
## Create vector holding the names of the input data to use when saving the output
output_names <- names(input_data.one_list)
all_results.glm.cutoff80.frame60 <- foreach(i = 1:length(input_data.one_list),
.combine = append,
.packages = c("mboost", "caret", "data.table")) %dopar%
{
tmp_results <- ultra_model(input_data.one_list[[i]], nIter = 2000,
shrinkage = 0.05, frame_size = 60)
to_save <- paste0("glm_results.", output_names[i])
assign(to_save, tmp_results)        #assign data to desired name
file_name <- paste0(to_save, ".rda") #create desired file name
save(list = to_save, file = file_name) #save data with desired names
##Print progress
print(paste0("Finished chunk: ", as.character(i), "/", as.character(length(input_data.one_list)),
" (", output_names[i], ")",
" at ", substr(as.character(Sys.time()), 1, 19)))
par_results <- list(tmp_results)
names(par_results) <- paste0(names(input_data.one_list[i]))
return(par_results)
}
save(all_results.glm.cutoff80.frame60, file = "all_results.glm.cutoff80.frame60.rda")
library(mboost)
library(caret)
library(data.table)
library(multilevelPSA)
library(doParallel)
this_folder <- getwd()
## The required data for all modelling
load(paste0(this_folder, "/subsets_lagged.rda"))
## Files that contain functions - they don't perform anything themselves
source(paste0(this_folder, "/corr_pruner.R"))
source(paste0(this_folder, "/error_functions.R"))
source(paste0(this_folder, "/results_template.R"))
source(paste0(this_folder, "/ultra_modeller.R"))
## =============================== ##
##  Setup for parallel processing  ##
## =============================== ##
registerDoParallel(8)
input_data <- sapply(c("Lag.1", "Lag.2", "Lag.3", "Lag.4", "Lag.5"), function(x) NULL)
input_subsets <- sapply(c("trad_small", "trad_large", "sent_small", "sent_large", "combined"), function(x) NULL)
for(i in 1:length(input_data)){input_data[[i]] <- input_subsets}
## Assistance:
## subsets_lagged[[4]][[3]]   --> first index is the lag value, here Lag.4 [(i-1) = lag]
##                            --> second index is the subset.  1 = trad_small
##                                                             2 = trad_large
##                                                             3 = sent_small
##                                                             4 = sent_large
##                                                             5 = combined
## Need to run this each time too to take a fresh copy of the data. DOW.DP is removed by reference otherwise
raw_data <- copy(subsets_lagged)
## for(i in 1:5) {
##     for(j in 1:5) {
##         input_data[[i]][[j]] <- corr_pruner(raw_data[[i]][[j]],
##                                             cutoff = 0.8,
##                                             plot = FALSE,
##                                             print.removed = FALSE)
##     }
## }
## ---------------------------------------------------------- ##
##  Flatten the list so that all available cores can be used  ##
## ---------------------------------------------------------- ##
## Flatten
input_data.one_list <- unlist(raw_data, recursive = FALSE)
## Create vector holding the names of the input data to use when saving the output
output_names <- names(input_data.one_list)
###################### ======================== ######################
######################  Run the data in a loop  ######################
###################### ======================== ######################
## ----------------------------------------- ##
##  Use foreach to work through all subsets  ##
## ----------------------------------------- ##
## Assig results to one parent object on top of saving each result individually
all_results.glm.no_cutoff.frame60 <- foreach(i = 1:length(input_data.one_list),
.combine = append,
.packages = c("mboost", "caret", "data.table")) %dopar%
{
tmp_results <- ultra_model(input_data.one_list[[i]], nIter = 2000,
shrinkage = 0.05, frame_size = 60)
to_save <- paste0("glm_results.", output_names[i])
assign(to_save, tmp_results)        #assign data to desired name
file_name <- paste0(to_save, ".rda") #create desired file name
save(list = to_save, file = file_name) #save data with desired names
##Print progress
print(paste0("Finished chunk: ", as.character(i), "/", as.character(length(input_data.one_list)),
" (", output_names[i], ")",
" at ", substr(as.character(Sys.time()), 1, 19)))
par_results <- list(tmp_results)
names(par_results) <- paste0(names(input_data.one_list[i]))
return(par_results)
}
save(all_results.glm.no_cutoff.frame60, file = "all_results.glm.no_cutoff.frame60.rda")
